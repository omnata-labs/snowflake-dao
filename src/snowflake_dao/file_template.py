"""_summary_
This file was generated by snowflake-dao and should not be directly modified.
"""
from __future__ import annotations
from abc import ABC
from snowflake.snowpark import Column
from snowflake.snowpark.functions import col, lit, when_matched, iff, to_timestamp,parse_json,to_varchar,object_construct,when_not_matched,sql_expr
from typing import Any, Dict, List,Optional
import typing
import json


class Sequence():
    def __init__(self,sequence_name:str):
        self.sequence_name = sequence_name
    def nextval(self,session):
        return session.sql(f"select {self.sequence_name}.nextval").collect()[0].NEXTVAL

class SnowflakeTable(ABC):
    def __repr__(self):
        return str({k:v for k,v in self.__dict__.items() if not k.startswith('_')})
    
    @classmethod
    def _create_object(cls,**kwargs):
        table_class=kwargs['table_class']
        session=kwargs['session']
        params = {x: kwargs[x] for x in kwargs if x not in ['cls','table_class','session']}
        print(kwargs)
        for k,v in params.items():
            if isinstance(v,Sequence):
                params[k] = v.nextval(session)
        # for now we're just using class name == table name
        target_table = session.table(table_class.__name__)
        dummy_df = session.create_dataframe([1], schema=["col_a"])
        # snowpark doesn't have an insert abstraction, so we use an unmatchable merge
        target_table \
                .merge(dummy_df,lit(1)==lit(0),
                    [when_not_matched().insert(params)])
        
        return table_class(session,**params)
    
    @classmethod
    def _lookup_by_id(cls,table_class,session,id_column:str,id_value:any) -> SnowflakeTable:
        results = session.table(table_class.__name__).where((col(id_column)==lit(id_value))).collect()
        if len(results) == 0:
            raise ValueError(f'No {table_class.__name__} found with {id_column} {id_value}')
        if len(results) > 1:
            raise ValueError(f'Too many results for {table_class.__name__} with {id_column} {id_value} ({len(results)})')
        result_dict = results[0].as_dict()
        type_hints = typing.get_type_hints(table_class.__init__)
        for k,v in result_dict.items():
            # properties without Optional typings are not allowed to be None
            if v is None:
                if typing.get_origin(type_hints[k])!=typing.Union or type(None) not in typing.get_args(type_hints[k]):
                    raise ValueError(f"A null value was found in column {k}, but it was marked as NOT NULL at the time of DAO generation")
                result_dict[k] = None
            else:
                actual_type = type_hints[k]
                # if it's an optional type but the value isn't null, we'll find the actual type to cast with
                if typing.get_origin(type_hints[k])==typing.Union:
                    actual_types = [t for t in typing.get_args(type_hints[k]) if t!=type(None)]
                    if len(actual_types)!=1:
                        raise ValueError(f"Can't determine the real type of column {k} based on its type hints ({type_hints[k]})")
                    actual_type = actual_types[0]
                if actual_type==int:
                    result_dict[k] = int(v)
                elif actual_type == typing.Dict:
                    result_dict[k] = json.loads(v) if v else None # Python connector returns strings for variant columns
        return table_class(session,**result_dict)

    @classmethod
    def _lookup_by_column_values(cls,table_class,session,columns:List[str],values:List[any],single_value_expected:bool) -> List[SnowflakeTable]:
        non_null_values = [v for v in values if v]
        if len(non_null_values)==0:
            # no point doing a lookup if no actual values were provided
            return None if single_value_expected else []
        if len(non_null_values) != len(values):
            raise ValueError("Performing a lookup is not supported when some of the foreign key values are null")
        if len(columns)!=len(values):
            raise ValueError(f"You must pass in the same number of columns and values (got {len(columns)} columns and {len(values)} values)")
        where_clauses = (lit(1)==lit(1))
        for index,column_name in enumerate(columns):
            where_clauses = where_clauses & (col(column_name)==lit(values[index]))
        results = session.table(table_class.__name__).where(where_clauses).collect()
        if single_value_expected:
            if len(results) == 0:
                raise ValueError(f"No matching {table_class} record was found, this should not be possible given the foreign key relationship at the time of DAO generation")
            if len(results) > 1:
                raise ValueError(f"Multiple matching {table_class} records were found, this should not be possible given the foreign key relationship at the time of DAO generation")
        return_values=[]
        for result in results:
            result_dict = result.as_dict()
            type_hints = typing.get_type_hints(table_class.__init__)
            for k,v in result_dict.items():
                if type_hints[k]==int:
                    result_dict[k] = int(v)
                elif type_hints[k] == typing.Dict:
                    result_dict[k] = json.loads(v) if v else None # Python connector returns strings for variant columns
            return_values.append(table_class(session,**result_dict))
        return return_values[0] if single_value_expected else return_values
